# Logstash Configuration for Aurigraph V11
# Stream 5: Production Monitoring & Deployment
#
# ELK Stack log aggregation and processing pipeline

input {
  # Application logs from file
  file {
    path => "/var/log/aurigraph-v11/application.log"
    start_position => "beginning"
    sincedb_path => "/var/lib/logstash/sincedb_aurigraph_app"
    codec => multiline {
      pattern => "^%{TIMESTAMP_ISO8601}"
      negate => true
      what => "previous"
    }
    tags => ["application"]
  }

  # Transaction logs
  file {
    path => "/var/log/aurigraph-v11/transactions.log"
    start_position => "beginning"
    sincedb_path => "/var/lib/logstash/sincedb_aurigraph_tx"
    codec => json
    tags => ["transactions"]
  }

  # Consensus logs
  file {
    path => "/var/log/aurigraph-v11/consensus.log"
    start_position => "beginning"
    sincedb_path => "/var/lib/logstash/sincedb_aurigraph_consensus"
    codec => json
    tags => ["consensus"]
  }

  # Security audit logs
  file {
    path => "/var/log/aurigraph-v11/security-audit.log"
    start_position => "beginning"
    sincedb_path => "/var/lib/logstash/sincedb_aurigraph_security"
    codec => json
    tags => ["security", "audit"]
  }

  # Bridge logs
  file {
    path => "/var/log/aurigraph-v11/bridge.log"
    start_position => "beginning"
    sincedb_path => "/var/lib/logstash/sincedb_aurigraph_bridge"
    codec => json
    tags => ["bridge"]
  }

  # Performance logs
  file {
    path => "/var/log/aurigraph-v11/performance.log"
    start_position => "beginning"
    sincedb_path => "/var/lib/logstash/sincedb_aurigraph_perf"
    codec => json
    tags => ["performance"]
  }

  # Error logs
  file {
    path => "/var/log/aurigraph-v11/error.log"
    start_position => "beginning"
    sincedb_path => "/var/lib/logstash/sincedb_aurigraph_error"
    codec => multiline {
      pattern => "^%{TIMESTAMP_ISO8601}"
      negate => true
      what => "previous"
    }
    tags => ["error"]
  }

  # Docker container logs (if running in containers)
  docker {
    image_id => "aurigraph-v11"
    container_id => "*"
    type => "docker"
    tags => ["docker", "container"]
  }

  # Beats input for Filebeat
  beats {
    port => 5044
    tags => ["beats"]
  }

  # TCP input for direct log shipping
  tcp {
    port => 5000
    codec => json_lines
    tags => ["tcp"]
  }

  # Syslog input
  syslog {
    port => 5514
    tags => ["syslog"]
  }
}

filter {
  # Parse application logs
  if "application" in [tags] {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} \[%{DATA:thread}\] %{DATA:logger} - %{GREEDYDATA:log_message}" }
    }
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }

  # Process transaction logs
  if "transactions" in [tags] {
    json {
      source => "message"
    }
    mutate {
      add_field => { "[@metadata][index_prefix]" => "aurigraph-transactions" }
    }
    # Calculate transaction processing time
    if [start_time] and [end_time] {
      ruby {
        code => "event.set('processing_time_ms', event.get('end_time') - event.get('start_time'))"
      }
    }
  }

  # Process consensus logs
  if "consensus" in [tags] {
    json {
      source => "message"
    }
    mutate {
      add_field => { "[@metadata][index_prefix]" => "aurigraph-consensus" }
    }
    # Enrich with consensus metrics
    if [node_state] {
      mutate {
        add_field => { "is_leader" => "%{node_state}" }
      }
      translate {
        field => "is_leader"
        destination => "is_leader"
        dictionary => {
          "LEADER" => "true"
          "FOLLOWER" => "false"
          "CANDIDATE" => "false"
        }
        fallback => "false"
      }
    }
  }

  # Process security audit logs
  if "security" in [tags] {
    json {
      source => "message"
    }
    mutate {
      add_field => { "[@metadata][index_prefix]" => "aurigraph-security" }
    }
    # Flag high-severity events
    if [severity] == "CRITICAL" or [severity] == "HIGH" {
      mutate {
        add_tag => [ "alert", "urgent" ]
      }
    }
    # Mask sensitive data
    if [user_data] {
      mutate {
        gsub => [
          "user_data", "(password|token|key)\":\s*\"[^\"]+\"", "\1\":\"***REDACTED***\""
        ]
      }
    }
  }

  # Process bridge logs
  if "bridge" in [tags] {
    json {
      source => "message"
    }
    mutate {
      add_field => { "[@metadata][index_prefix]" => "aurigraph-bridge" }
    }
    # Calculate bridge completion time
    if [initiated_at] and [completed_at] {
      ruby {
        code => "event.set('bridge_duration_ms', event.get('completed_at') - event.get('initiated_at'))"
      }
    }
  }

  # Process performance logs
  if "performance" in [tags] {
    json {
      source => "message"
    }
    mutate {
      add_field => { "[@metadata][index_prefix]" => "aurigraph-performance" }
    }
    # Flag performance degradation
    if [tps] {
      if [tps] < 100000 {
        mutate {
          add_tag => [ "performance_degradation", "alert" ]
        }
      }
    }
    if [p99_latency_ms] {
      if [p99_latency_ms] > 500 {
        mutate {
          add_tag => [ "high_latency", "alert" ]
        }
      }
    }
  }

  # Process error logs
  if "error" in [tags] {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} \[%{DATA:thread}\] %{DATA:logger} - %{GREEDYDATA:error_message}" }
    }
    # Extract stack traces
    if [message] =~ /Exception|Error/ {
      grok {
        match => { "message" => "(?<exception_type>[A-Za-z.]+Exception)" }
      }
      mutate {
        add_tag => [ "exception", "alert" ]
      }
    }
  }

  # Add common fields
  mutate {
    add_field => {
      "environment" => "production"
      "platform" => "aurigraph-v11"
      "service" => "blockchain"
    }
  }

  # GeoIP enrichment for IP addresses
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "agent", "ecs", "input", "log" ]
  }
}

output {
  # Index by log type and date
  if [@metadata][index_prefix] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOSTS:elasticsearch:9200}"]
      index => "%{[@metadata][index_prefix]}-%{+YYYY.MM.dd}"
      user => "${ELASTICSEARCH_USERNAME:elastic}"
      password => "${ELASTICSEARCH_PASSWORD:changeme}"
      ssl_certificate_verification => true
      cacert => "/etc/logstash/certs/ca.crt"
    }
  } else {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOSTS:elasticsearch:9200}"]
      index => "aurigraph-v11-%{+YYYY.MM.dd}"
      user => "${ELASTICSEARCH_USERNAME:elastic}"
      password => "${ELASTICSEARCH_PASSWORD:changeme}"
      ssl_certificate_verification => true
      cacert => "/etc/logstash/certs/ca.crt"
    }
  }

  # Send alerts to separate index
  if "alert" in [tags] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOSTS:elasticsearch:9200}"]
      index => "aurigraph-alerts-%{+YYYY.MM.dd}"
      user => "${ELASTICSEARCH_USERNAME:elastic}"
      password => "${ELASTICSEARCH_PASSWORD:changeme}"
      ssl_certificate_verification => true
      cacert => "/etc/logstash/certs/ca.crt"
    }
  }

  # Send security events to dedicated index
  if "security" in [tags] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOSTS:elasticsearch:9200}"]
      index => "aurigraph-security-%{+YYYY.MM.dd}"
      user => "${ELASTICSEARCH_USERNAME:elastic}"
      password => "${ELASTICSEARCH_PASSWORD:changeme}"
      ssl_certificate_verification => true
      cacert => "/etc/logstash/certs/ca.crt"
    }
  }

  # Stdout for debugging (remove in production)
  if [@metadata][debug] {
    stdout {
      codec => rubydebug
    }
  }

  # Dead letter queue for failed events
  dead_letter_queue {
    enable => true
    max_bytes => "1gb"
    flush_interval => 5000
  }
}
